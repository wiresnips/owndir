


Let's review the current state of this project

	Central is a general framework for generating a webview of the contents of a folder

	As of right now, it's very STATIC generation, which I'm not sure is a problem




	The plan is to pop open a folder and run a slug of "build" javascript,
	which outputs an {} object that can be used to populate a template 
		(the template can also be specified per folder)

	That's about as specific as we've gotten so far.




	So, calling build(dir) will recurse through directories, running each directory's specific build
	This will result in a templated object, and maybe also a template, which can be slammed together to make an html page

	the html page get sorta dumped there, and you can go visit it in a browser
	(there will also need to be a server, but it can be pretty dumb at the moment)





	GhettoMint
		- Scraper dumps results into a CSV
		- build converts CSV into JSON, and templates something for the display


	


	What's the current barrier?
		I want to understand how to manage dependencies in the build scripts
		I want to understand how to EXECUTE the build scripts
		

























Okay, this is spiralling out of control in my head. Pull it back under control.

	this is a strong general structure
		- human readable viewed locally
		- very extensible viewed remotely

	DON'T need to build it all out at once.
		
		FIRST PRIORITY is the banking dash
			
			1) scraper pulls data
				- saves it in a nice plaintext format, probably just a single CSV

			2) builder recursively compiles folders
				- instructions inside the folder can help with this (?)

			3) profit ?
				- I guess I need some kind of a server, too?
				  All the magic is definitely happening in step 2, though




		SECOND PRIORITY is the knowledge base

































Okay, let's think about what I want

	DOCUMENTS
		I want to be able to save documents like in a filesystem, but also TAG them

	CALENDAR
		create events
		create reminders
		attach contacts ?
		attach DOCUMENTS (I'm thinking here specifically about tickets)

	CONTACTS
		yes please, let's get a personal backup of this info

	FINANCE

	BOOKMARKS (?)

	MARKDOWN

	ALERTS

	PROJECTS

	KNOWLEDGE BASE

		Editable wiki?

		internal crosslinks?









Let's say we have a filesystem, and we just slam a bunch of stuff into it

For each folder, we can have an `index.html`, and we just run a VERY basic webserver. We can even have  other views, like `raw.html`


Let's furthermore say, we have some kind of a "build" process that will crawl through the filesystem, generating these HTML files



Basically, I'm thinking about a mashup between blosxom and Tiddly


So, there's some kind of `main.dash` file or something, that will get parsed and slammed into the index file

	main.dash is mostly markdown, but with a way to slam in some javascript
 
 	the static processing ALSO builds a local object that reflects the contents of the folder, which the javascript can use


And, once I've got this preprocessing markdown folder info structure, AND I've got markdown and javascript, I can build whatever god damned thing I want out of it




Okay, that sounds pretty cool, and has a lot of potential, BUT - why do I care about putting it on the internet in the first place? Like, I can do this with a folder. 

	I want the DASHBOARD aspect (but this might just be a re-training issue)

	I want remote access (but this is incidental, and I always have my laptop anyways)

	I want a nicer interface maybe?



	Yeah, I think the main goal would be something LIKE tiddly, but that was accessible from both directions













